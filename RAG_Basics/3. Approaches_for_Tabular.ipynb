{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1275150c",
   "metadata": {
    "id": "3d50f6b3"
   },
   "source": [
    "# Notebook 3: Approaches for Tabular Data\n",
    "\n",
    "In this notebook we will show a few ways to use LLM pipelines with tabular data. I like to think of working with tabular data with LLMs with 3 options.\n",
    "\n",
    "1. **Static Approach:** Store data in a knowledge base and try to retrieve the relevant data to answer the question directly\n",
    "2. **Templated Code / Function Calling Approach:** Have pre-defined code that can run to satisfy certain requests. Extract inputs and produce answer using outputs with LLMs.\n",
    "3. **AI Agent Approach:** The LLM creates code to run in order to produce analysis required to answer the question.\n",
    " \n",
    "Complexity and reliance on the LLM increases from 1. where no code is executed to 2. where only pre-define coded is executed to 3. where the LLM produces code to execute. The separation is not perfectly clean agents can also just point only to pre-defined code, but this is just a framework. Additionally, for 1., the stored data could consist of extensively pre-process \"views\" of the data aimed at satisfying the majority of user queries. \n",
    "\n",
    "In this notebook, we will focus on 1. and 3., but demonstrate 2. through the use of agents to some extent. We will consider on Tesla (TSLA) stock prices data.\n",
    "* First, we will use the common approach of using LangChain's [CSV Loader](https://python.langchain.com/docs/integrations/document_loaders/csv)\n",
    "* Next, we will explore Langchain's [TimeWeightedVectorStoreRetriever](https://python.langchain.com/docs/modules/data_connection/retrievers/time_weighted_vectorstore) and learn why this may not be what we want\n",
    "* Then, we will explore using agent based approaches from [LangChain](https://github.com/langchain-ai/langchain/tree/master) and [Pandas-AI](https://github.com/Sinaptik-AI/pandas-ai/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a23f9e06"
   },
   "source": [
    "## Import libraries and load the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e6737a",
   "metadata": {
    "chart_settings": null,
    "custom_metric_settings": null,
    "dataframe_view_options": null,
    "datarobot": {
     "language": "python"
    },
    "disable_run": null,
    "hide_code": null,
    "hide_results": null,
    "id": "64e51b8d4fcea0e1deb7dcf3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import faiss\n",
    "\n",
    "#We will use langchain to create a vector store to retrieve stronger negatives\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, csv_loader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.utils import mock_now\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"## \"BAAI/bge-base-en-v1.5\"\"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "489a10f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b8f31f",
   "metadata": {
    "id": "71be0425",
    "outputId": "6a0e02bd-0e6a-413a-c7c2-c985c2c7b246"
   },
   "outputs": [],
   "source": [
    "#load stock data. Load dataframe and load directly as docs\n",
    "tsla_stock = pd.read_csv(\"../data/TSLA.csv\")\n",
    "spy_etf = pd.read_csv(\"../data/SPY.csv\") #for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3913892"
   },
   "source": [
    "## Static Approaches \n",
    "\n",
    "Here we use a knowledge base of TSLA's stock data\n",
    "\n",
    "#### Using LangChain's CSVLoader\n",
    "This just loads each record as a json in an individual document in our vector database to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5acb2e9",
   "metadata": {
    "id": "4433b705"
   },
   "outputs": [],
   "source": [
    "loader  = csv_loader.CSVLoader(file_path=\"../data/TSLA.csv\")\n",
    "stock_data_docs = loader.load()\n",
    "stock_data_docs[0]\n",
    "\n",
    "#for the retrieval process\n",
    "embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL_NAME,\n",
    "        cache_folder=\"../models/sentencetransformers\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a6e61e",
   "metadata": {
    "id": "d0a4c7ea",
    "outputId": "815b32ef-e287-4be3-9c64-2ad24cdba83f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2010-06-29\\nOpen: 1.266667\\nHigh: 1.666667\\nLow: 1.169333\\nClose: 1.592667\\nAdj Close: 1.592667\\nVolume: 281494500', metadata={'source': '../data/TSLA.csv', 'row': 0, 'last_accessed_at': datetime.datetime(2010, 6, 29, 0, 0)})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first let's add more context to help with Retrieval and add date to metadata (for later use)\n",
    "for ii in range(0, len(stock_data_docs)):\n",
    "    stock_data_docs[ii].page_content = \"Daily stock market data for Tesla (TSLA):\\n\" + stock_data_docs[ii].page_content\n",
    "    date = re.findall(r'Date: (\\d{4}-\\d{2}-\\d{2})', stock_data_docs[ii].page_content)\n",
    "    if len(date) > 0:\n",
    "        stock_data_docs[ii].metadata['last_accessed_at'] = datetime.strptime(date[0], '%Y-%m-%d')\n",
    "    else:\n",
    "        stock_data_docs[ii].metadata['last_accessed_at'] = None\n",
    "stock_data_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187f0d40",
   "metadata": {
    "id": "59dfff73"
   },
   "outputs": [],
   "source": [
    "db_data = FAISS.from_documents(stock_data_docs, embedding_function)\n",
    "db_data.save_local(\"../data/faiss_stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efd720ab"
   },
   "source": [
    "Our stock data is just through 2024-02-02 so we will specify that as today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed95b3ee",
   "metadata": {
    "id": "b0305479"
   },
   "outputs": [],
   "source": [
    "top_k=16\n",
    "retriever_stock = VectorStoreRetriever(vectorstore=db_data, search_kwargs={\"k\": top_k})\n",
    "\n",
    "def generate_response(prompt, retriever):\n",
    "    #today's date - let's pretend it is 2024-02-02\n",
    "    today = \"2024-02-02\"\n",
    "    #replace \"current\" or \"today\" with today's date\n",
    "    prompt = re.sub(r'current|today', today, prompt, flags=re.IGNORECASE)\n",
    "    print(\"Prompt: \", prompt)\n",
    "    # Get the top k most similar documents\n",
    "    results = retriever.get_relevant_documents(prompt)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64315a68",
   "metadata": {
    "id": "46ea2ac9",
    "outputId": "adf2c389-592c-42c4-f0c6-8126c84a3200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  What is TSLA's 2024-02-02 close price?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2021-08-03\\nOpen: 239.666672\\nHigh: 240.883331\\nLow: 233.669998\\nClose: 236.580002\\nAdj Close: 236.580002\\nVolume: 64860900', metadata={'source': '../data/TSLA.csv', 'row': 2793, 'last_accessed_at': datetime.datetime(2021, 8, 3, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2021-04-20\\nOpen: 239.139999\\nHigh: 245.750000\\nLow: 236.896667\\nClose: 239.663330\\nAdj Close: 239.663330\\nVolume: 106827000', metadata={'source': '../data/TSLA.csv', 'row': 2720, 'last_accessed_at': datetime.datetime(2021, 4, 20, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-08-18\\nOpen: 306.000000\\nHigh: 306.500000\\nLow: 301.853333\\nClose: 302.869995\\nAdj Close: 302.869995\\nVolume: 47500500', metadata={'source': '../data/TSLA.csv', 'row': 3056, 'last_accessed_at': datetime.datetime(2022, 8, 18, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2023-10-25\\nOpen: 215.880005\\nHigh: 220.100006\\nLow: 212.199997\\nClose: 212.419998\\nAdj Close: 212.419998\\nVolume: 107065100', metadata={'source': '../data/TSLA.csv', 'row': 3354, 'last_accessed_at': datetime.datetime(2023, 10, 25, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2023-12-04\\nOpen: 235.750000\\nHigh: 239.369995\\nLow: 233.289993\\nClose: 235.580002\\nAdj Close: 235.580002\\nVolume: 104099800', metadata={'source': '../data/TSLA.csv', 'row': 3381, 'last_accessed_at': datetime.datetime(2023, 12, 4, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-12-19\\nOpen: 154.000000\\nHigh: 155.250000\\nLow: 145.820007\\nClose: 149.869995\\nAdj Close: 149.869995\\nVolume: 139390600', metadata={'source': '../data/TSLA.csv', 'row': 3141, 'last_accessed_at': datetime.datetime(2022, 12, 19, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-07-15\\nOpen: 240.000000\\nHigh: 243.623337\\nLow: 236.889999\\nClose: 240.066666\\nAdj Close: 240.066666\\nVolume: 69683100', metadata={'source': '../data/TSLA.csv', 'row': 3032, 'last_accessed_at': datetime.datetime(2022, 7, 15, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2021-01-06\\nOpen: 252.830002\\nHigh: 258.000000\\nLow: 249.699997\\nClose: 251.993332\\nAdj Close: 251.993332\\nVolume: 134100000', metadata={'source': '../data/TSLA.csv', 'row': 2649, 'last_accessed_at': datetime.datetime(2021, 1, 6, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2023-02-17\\nOpen: 199.990005\\nHigh: 208.440002\\nLow: 197.500000\\nClose: 208.309998\\nAdj Close: 208.309998\\nVolume: 213738500', metadata={'source': '../data/TSLA.csv', 'row': 3182, 'last_accessed_at': datetime.datetime(2023, 2, 17, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-05-02\\nOpen: 286.923340\\nHigh: 302.119995\\nLow: 282.676666\\nClose: 300.980011\\nAdj Close: 300.980011\\nVolume: 75781500', metadata={'source': '../data/TSLA.csv', 'row': 2981, 'last_accessed_at': datetime.datetime(2022, 5, 2, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-09-16\\nOpen: 299.609985\\nHigh: 303.709991\\nLow: 295.600006\\nClose: 303.350006\\nAdj Close: 303.350006\\nVolume: 87087800', metadata={'source': '../data/TSLA.csv', 'row': 3076, 'last_accessed_at': datetime.datetime(2022, 9, 16, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2023-02-21\\nOpen: 204.990005\\nHigh: 209.710007\\nLow: 197.220001\\nClose: 197.369995\\nAdj Close: 197.369995\\nVolume: 180018600', metadata={'source': '../data/TSLA.csv', 'row': 3183, 'last_accessed_at': datetime.datetime(2023, 2, 21, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2021-08-12\\nOpen: 235.446671\\nHigh: 240.933334\\nLow: 233.133331\\nClose: 240.750000\\nAdj Close: 240.750000\\nVolume: 52377300', metadata={'source': '../data/TSLA.csv', 'row': 2800, 'last_accessed_at': datetime.datetime(2021, 8, 12, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-10-25\\nOpen: 210.100006\\nHigh: 224.350006\\nLow: 210.000000\\nClose: 222.419998\\nAdj Close: 222.419998\\nVolume: 96507900', metadata={'source': '../data/TSLA.csv', 'row': 3103, 'last_accessed_at': datetime.datetime(2022, 10, 25, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-11-04\\nOpen: 222.600006\\nHigh: 223.800003\\nLow: 203.080002\\nClose: 207.470001\\nAdj Close: 207.470001\\nVolume: 98622200', metadata={'source': '../data/TSLA.csv', 'row': 3111, 'last_accessed_at': datetime.datetime(2022, 11, 4, 0, 0)}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-10-12\\nOpen: 215.330002\\nHigh: 219.300003\\nLow: 211.509995\\nClose: 217.240005\\nAdj Close: 217.240005\\nVolume: 66860700', metadata={'source': '../data/TSLA.csv', 'row': 3094, 'last_accessed_at': datetime.datetime(2022, 10, 12, 0, 0)})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =\"What is TSLA's current close price?\"\n",
    "generate_response(question, retriever_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65c1b2c0"
   },
   "source": [
    "Notice that even when we replace \"current\" with today's date, our retrieval process is not strong enough to only pick recent dates. \n",
    "\n",
    "Let's try using TimeWeightedVectorStoreRetriever to bias towards recent dates...<br>\n",
    "\n",
    "#### TimeWeightedVectorStoreRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09949529",
   "metadata": {
    "id": "01000f57",
    "outputId": "2b71eb7d-d3f9-445a-db68-eda936f5d96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  What is TSLA's 2024-02-02 close price?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-02-02\\nOpen: 185.039993\\nHigh: 188.690002\\nLow: 182.000000\\nClose: 187.910004\\nAdj Close: 187.910004\\nVolume: 110505100', metadata={'source': '../data/TSLA.csv', 'row': 3422, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3422}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-02-01\\nOpen: 188.500000\\nHigh: 189.880005\\nLow: 184.279999\\nClose: 188.860001\\nAdj Close: 188.860001\\nVolume: 91843300', metadata={'source': '../data/TSLA.csv', 'row': 3421, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3421}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-31\\nOpen: 187.000000\\nHigh: 193.970001\\nLow: 185.850006\\nClose: 187.289993\\nAdj Close: 187.289993\\nVolume: 103221400', metadata={'source': '../data/TSLA.csv', 'row': 3420, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3420}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-30\\nOpen: 195.330002\\nHigh: 196.360001\\nLow: 190.610001\\nClose: 191.589996\\nAdj Close: 191.589996\\nVolume: 109982300', metadata={'source': '../data/TSLA.csv', 'row': 3419, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3419}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-29\\nOpen: 185.630005\\nHigh: 191.479996\\nLow: 183.669998\\nClose: 190.929993\\nAdj Close: 190.929993\\nVolume: 125013100', metadata={'source': '../data/TSLA.csv', 'row': 3418, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3418}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-22\\nOpen: 212.259995\\nHigh: 217.800003\\nLow: 206.270004\\nClose: 208.800003\\nAdj Close: 208.800003\\nVolume: 117952500', metadata={'source': '../data/TSLA.csv', 'row': 3413, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3413}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-26\\nOpen: 185.500000\\nHigh: 186.779999\\nLow: 182.100006\\nClose: 183.250000\\nAdj Close: 183.250000\\nVolume: 107343200', metadata={'source': '../data/TSLA.csv', 'row': 3417, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3417}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-25\\nOpen: 189.699997\\nHigh: 193.000000\\nLow: 180.059998\\nClose: 182.630005\\nAdj Close: 182.630005\\nVolume: 198076800', metadata={'source': '../data/TSLA.csv', 'row': 3416, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3416}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-04\\nOpen: 239.250000\\nHigh: 242.699997\\nLow: 237.729996\\nClose: 237.929993\\nAdj Close: 237.929993\\nVolume: 102629300', metadata={'source': '../data/TSLA.csv', 'row': 3402, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3402}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2024-01-02\\nOpen: 250.080002\\nHigh: 251.250000\\nLow: 244.410004\\nClose: 248.419998\\nAdj Close: 248.419998\\nVolume: 104654200', metadata={'source': '../data/TSLA.csv', 'row': 3400, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3400}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2021-08-03\\nOpen: 239.666672\\nHigh: 240.883331\\nLow: 233.669998\\nClose: 236.580002\\nAdj Close: 236.580002\\nVolume: 64860900', metadata={'source': '../data/TSLA.csv', 'row': 2793, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 2793}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2021-04-20\\nOpen: 239.139999\\nHigh: 245.750000\\nLow: 236.896667\\nClose: 239.663330\\nAdj Close: 239.663330\\nVolume: 106827000', metadata={'source': '../data/TSLA.csv', 'row': 2720, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 2720}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-08-18\\nOpen: 306.000000\\nHigh: 306.500000\\nLow: 301.853333\\nClose: 302.869995\\nAdj Close: 302.869995\\nVolume: 47500500', metadata={'source': '../data/TSLA.csv', 'row': 3056, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3056}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2023-10-25\\nOpen: 215.880005\\nHigh: 220.100006\\nLow: 212.199997\\nClose: 212.419998\\nAdj Close: 212.419998\\nVolume: 107065100', metadata={'source': '../data/TSLA.csv', 'row': 3354, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3354}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2023-12-04\\nOpen: 235.750000\\nHigh: 239.369995\\nLow: 233.289993\\nClose: 235.580002\\nAdj Close: 235.580002\\nVolume: 104099800', metadata={'source': '../data/TSLA.csv', 'row': 3381, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3381}),\n",
       " Document(page_content='Daily stock market data for Tesla (TSLA):\\nDate: 2022-12-19\\nOpen: 154.000000\\nHigh: 155.250000\\nLow: 145.820007\\nClose: 149.869995\\nAdj Close: 149.869995\\nVolume: 139390600', metadata={'source': '../data/TSLA.csv', 'row': 3141, 'last_accessed_at': MockDateTime(2024, 2, 2, 23, 0), 'created_at': datetime.datetime(2024, 3, 27, 10, 23, 4, 663286), 'buffer_idx': 3141})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1\n",
    "embedding_size = len(embedding_function.embed_documents([question])[0])\n",
    "index = faiss.IndexFlatL2(384)\n",
    "vectorstore = FAISS(embedding_function, index, InMemoryDocstore({}), {})\n",
    "tw_retriever_stock = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore,decay_rate=0.005, k=top_k)\n",
    "# Notice the last access time is that date time\n",
    "tw_retriever_stock.add_documents(stock_data_docs)\n",
    "with mock_now(datetime(2024, 2, 2, 23, 0)):\n",
    "    rel_docs = generate_response(question, tw_retriever_stock)\n",
    "rel_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eeb8bf",
   "metadata": {
    "id": "95f99f8e"
   },
   "source": [
    "This technically worked, but is not what we want. The 'last_accessed_at' was updated so it is not longer using the date for the stock and this will hurt performance when asking for previous dates. Let's try agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1c069",
   "metadata": {},
   "source": [
    "## Agent-based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3973165"
   },
   "source": [
    "#### Langchain CSV / Pandas Agents\n",
    "\n",
    "Here we will show simple use of Langchain [csv](https://python.langchain.com/docs/integrations/toolkits/csv) and [Pandas](https://python.langchain.com/docs/integrations/toolkits/pandas) agents. The csv agent uses the Pandas agent under the hood so we will just use the pandas agent directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f9ab5900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b482ec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.169333</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>281494500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>1.719333</td>\n",
       "      <td>2.028000</td>\n",
       "      <td>1.553333</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>257806500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.728000</td>\n",
       "      <td>1.351333</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>123282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>1.247333</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>77097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>1.074000</td>\n",
       "      <td>1.074000</td>\n",
       "      <td>103003500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close     Volume\n",
       "0  2010-06-29  1.266667  1.666667  1.169333  1.592667   1.592667  281494500\n",
       "1  2010-06-30  1.719333  2.028000  1.553333  1.588667   1.588667  257806500\n",
       "2  2010-07-01  1.666667  1.728000  1.351333  1.464000   1.464000  123282000\n",
       "3  2010-07-02  1.533333  1.540000  1.247333  1.280000   1.280000   77097000\n",
       "4  2010-07-06  1.333333  1.333333  1.055333  1.074000   1.074000  103003500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef5c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_agent(agent, prompt, verbose=True):\n",
    "    response = None\n",
    "    try:\n",
    "        response = agent.invoke(prompt, verbose=verbose)\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1b660",
   "metadata": {},
   "source": [
    "#### First we'll try the ZERO_SHOT_REACT_DESCRIPTION agent\n",
    "\n",
    "**Warning:** this does not work well\n",
    "\n",
    "**Also, it works much better with Langchain's [ChatOpenAI](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/chat_models/openai.py#L351) that just Langchain's [OpenAI](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/llms/openai.py#L731) which is used in the zero shot example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ec7c8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "# llm = OpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "agent = create_pandas_dataframe_agent(llm, tsla_stock, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "226f98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the most recent close price for TSLA, I need to look at the last row of the dataframe and get the value from the 'Close' column.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df.tail(1)['Close'].iloc[0]\u001b[0m\u001b[36;1m\u001b[1;3m187.910004\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The most recent close price for TSLA was $187.91.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What was the most recent close price for TSLA?', 'output': 'The most recent close price for TSLA was $187.91.'}\n"
     ]
    }
   ],
   "source": [
    "response = try_agent(agent, \"What was the most recent close price for TSLA?\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "663ce42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to calculate the standard deviation of the changes in open prices and the changes in close prices. The change can be calculated by subtracting the previous day's price from the current day's price. I will use the `diff()` method to calculate the changes and then the `std()` method to calculate the standard deviation for both 'Open' and 'Close' columns.\n",
      "\n",
      "Action: Calculate the standard deviation of the changes in open prices.\n",
      "Action Input: df['Open'].diff().std()\n",
      "\u001b[0mCalculate the standard deviation of the changes in open prices. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI need to use the python_repl_ast tool to execute the Python command.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Open'].diff().std()\u001b[0m\u001b[36;1m\u001b[1;3m4.945367157862929\u001b[0m\u001b[32;1m\u001b[1;3mThe standard deviation of the changes in open prices is approximately 4.945.\n",
      "\n",
      "Action: Calculate the standard deviation of the changes in close prices.\n",
      "Action Input: df['Close'].diff().std()\u001b[0mCalculate the standard deviation of the changes in close prices. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mI need to use the python_repl_ast tool to execute the Python command.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Close'].diff().std()\u001b[0m\u001b[36;1m\u001b[1;3m4.678933840976249\u001b[0m\u001b[32;1m\u001b[1;3mThe standard deviation of the changes in close prices is approximately 4.679.\n",
      "\n",
      "Thought: Now that I have both standard deviations, I can compare them to determine which one is larger.\n",
      "\n",
      "Final Answer: The change in open prices has a larger standard deviation (approximately 4.945) compared to the change in close prices (approximately 4.679).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Does the change in open or close prices have a larger standard deviation?', 'output': 'The change in open prices has a larger standard deviation (approximately 4.945) compared to the change in close prices (approximately 4.679).'}\n"
     ]
    }
   ],
   "source": [
    "response = try_agent(agent, \"Does the change in open or close prices have a larger standard deviation?\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfdc50",
   "metadata": {},
   "source": [
    "That sort-of worked when I ran it (sometimes errors). Sometimes we can see that it enters another step. \n",
    "\n",
    " We can look at [Langchain's default code](https://github.com/langchain-ai/langchain/blob/master/libs/experimental/langchain_experimental/agents/agent_toolkits/pandas/base.py) and [prompts](https://github.com/langchain-ai/langchain/blob/master/libs/experimental/langchain_experimental/agents/agent_toolkits/pandas/prompt.py) to see how we can improve it and work around bugs.\n",
    "\n",
    "The issue is in part related to a bug in Langchain. Let's use a work around and define out own prompt (which we will see another very minor bug).\n",
    "\n",
    "- **Bug 1:** The stop token in the React Agent is \\nObservation, but needs to be \\nFinal Answer for Pandas agent\n",
    "- **Bug 2:** \"create_pandas_dataframe_agent\" requiring include_df_in_prompt to be None vs False.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d42d0e",
   "metadata": {},
   "source": [
    "Building our own prompts for the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6e594d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"\n",
    "You are a large language model being used in an agent workflow involving questions, thoughts, use of tools, and actions using those tools. One of those tools allows you to work with a pandas dataframe in Python. The name of the dataframe is `df`.\n",
    "You should use the tools below to answer the question posed of you:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ce730dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3423</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>3423.000000</td>\n",
       "      <td>3.423000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>71.463546</td>\n",
       "      <td>73.027288</td>\n",
       "      <td>69.772792</td>\n",
       "      <td>71.436731</td>\n",
       "      <td>71.436731</td>\n",
       "      <td>9.690499e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>101.915934</td>\n",
       "      <td>104.171288</td>\n",
       "      <td>99.425029</td>\n",
       "      <td>101.828184</td>\n",
       "      <td>101.828184</td>\n",
       "      <td>7.980646e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.076000</td>\n",
       "      <td>1.108667</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>1.053333</td>\n",
       "      <td>1.053333</td>\n",
       "      <td>1.777500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.870667</td>\n",
       "      <td>11.166334</td>\n",
       "      <td>10.688667</td>\n",
       "      <td>10.945000</td>\n",
       "      <td>10.945000</td>\n",
       "      <td>4.623000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.025333</td>\n",
       "      <td>17.266666</td>\n",
       "      <td>16.719334</td>\n",
       "      <td>16.999332</td>\n",
       "      <td>16.999332</td>\n",
       "      <td>8.160300e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>122.324997</td>\n",
       "      <td>126.674999</td>\n",
       "      <td>119.958332</td>\n",
       "      <td>123.389999</td>\n",
       "      <td>123.389999</td>\n",
       "      <td>1.232748e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>411.470001</td>\n",
       "      <td>414.496674</td>\n",
       "      <td>405.666656</td>\n",
       "      <td>409.970001</td>\n",
       "      <td>409.970001</td>\n",
       "      <td>9.140820e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st_row</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.169333</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>2.814945e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd_row</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>1.719333</td>\n",
       "      <td>2.028000</td>\n",
       "      <td>1.553333</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>2.578065e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd_last_row</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>189.880005</td>\n",
       "      <td>184.279999</td>\n",
       "      <td>188.860001</td>\n",
       "      <td>188.860001</td>\n",
       "      <td>9.184330e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_row</th>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>185.039993</td>\n",
       "      <td>188.690002</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>187.910004</td>\n",
       "      <td>187.910004</td>\n",
       "      <td>1.105051e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date         Open         High          Low        Close  \\\n",
       "count               3423  3423.000000  3423.000000  3423.000000  3423.000000   \n",
       "unique              3423          NaN          NaN          NaN          NaN   \n",
       "top           2010-06-29          NaN          NaN          NaN          NaN   \n",
       "freq                   1          NaN          NaN          NaN          NaN   \n",
       "mean                 NaN    71.463546    73.027288    69.772792    71.436731   \n",
       "std                  NaN   101.915934   104.171288    99.425029   101.828184   \n",
       "min                  NaN     1.076000     1.108667     0.998667     1.053333   \n",
       "25%                  NaN    10.870667    11.166334    10.688667    10.945000   \n",
       "50%                  NaN    17.025333    17.266666    16.719334    16.999332   \n",
       "75%                  NaN   122.324997   126.674999   119.958332   123.389999   \n",
       "max                  NaN   411.470001   414.496674   405.666656   409.970001   \n",
       "1st_row       2010-06-29     1.266667     1.666667     1.169333     1.592667   \n",
       "2nd_row       2010-06-30     1.719333     2.028000     1.553333     1.588667   \n",
       "2nd_last_row  2024-02-01   188.500000   189.880005   184.279999   188.860001   \n",
       "last_row      2024-02-02   185.039993   188.690002   182.000000   187.910004   \n",
       "\n",
       "                Adj Close        Volume  \n",
       "count         3423.000000  3.423000e+03  \n",
       "unique                NaN           NaN  \n",
       "top                   NaN           NaN  \n",
       "freq                  NaN           NaN  \n",
       "mean            71.436731  9.690499e+07  \n",
       "std            101.828184  7.980646e+07  \n",
       "min              1.053333  1.777500e+06  \n",
       "25%             10.945000  4.623000e+07  \n",
       "50%             16.999332  8.160300e+07  \n",
       "75%            123.389999  1.232748e+08  \n",
       "max            409.970001  9.140820e+08  \n",
       "1st_row          1.592667  2.814945e+08  \n",
       "2nd_row          1.588667  2.578065e+08  \n",
       "2nd_last_row   188.860001  9.184330e+07  \n",
       "last_row       187.910004  1.105051e+08  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_stock.describe(include='all')\n",
    "#add first 2 rows and last 2 rows to describe\n",
    "df_describe = tsla_stock.describe(include='all')\n",
    "df_describe.loc['1st_row'] = tsla_stock.iloc[0]\n",
    "df_describe.loc['2nd_row'] = tsla_stock.iloc[1]\n",
    "df_describe.loc['2nd_last_row'] = tsla_stock.iloc[-2]\n",
    "df_describe.loc['last_row'] = tsla_stock.iloc[-1]\n",
    "df_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "eecbdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUFFIX_WITH_DF_DESCRIBE = \"\"\"\n",
    "You must STOP once you found the final answer. This is the result of running:\n",
    "\n",
    "df_describe = df.describe(include='all')\n",
    "df_describe.loc['1st_row'] = df.iloc[0]\n",
    "df_describe.loc['2nd_row'] = df.iloc[1]\n",
    "df_describe.loc['2nd_last_row'] = df.iloc[-2]\n",
    "df_describe.loc['last_row'] = df.iloc[-1]\n",
    "print(df_describe.to_markdown())\n",
    "del df_describe:\n",
    "{df_describe}\n",
    "\n",
    "Please note that python_repl_ast cannot use df_decribe, but can use df.\n",
    "\n",
    "Begin!\n",
    "Question: {{input}}\n",
    "{{agent_scratchpad}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f5d43a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You must STOP once you found the final answer. This is the result of running:\n",
      "\n",
      "df_describe = df.describe(include='all')\n",
      "df_describe.loc['1st_row'] = df.iloc[0]\n",
      "df_describe.loc['2nd_row'] = df.iloc[1]\n",
      "df_describe.loc['2nd_last_row'] = df.iloc[-2]\n",
      "df_describe.loc['last_row'] = df.iloc[-1]\n",
      "print(df_describe.to_markdown())\n",
      "del df_describe:\n",
      "|              | Date       |       Open |       High |         Low |      Close |   Adj Close |         Volume |\n",
      "|:-------------|:-----------|-----------:|-----------:|------------:|-----------:|------------:|---------------:|\n",
      "| count        | 3423       | 3423       | 3423       | 3423        | 3423       |  3423       | 3423           |\n",
      "| unique       | 3423       |  nan       |  nan       |  nan        |  nan       |   nan       |  nan           |\n",
      "| top          | 2010-06-29 |  nan       |  nan       |  nan        |  nan       |   nan       |  nan           |\n",
      "| freq         | 1          |  nan       |  nan       |  nan        |  nan       |   nan       |  nan           |\n",
      "| mean         | nan        |   71.4635  |   73.0273  |   69.7728   |   71.4367  |    71.4367  |    9.6905e+07  |\n",
      "| std          | nan        |  101.916   |  104.171   |   99.425    |  101.828   |   101.828   |    7.98065e+07 |\n",
      "| min          | nan        |    1.076   |    1.10867 |    0.998667 |    1.05333 |     1.05333 |    1.7775e+06  |\n",
      "| 25%          | nan        |   10.8707  |   11.1663  |   10.6887   |   10.945   |    10.945   |    4.623e+07   |\n",
      "| 50%          | nan        |   17.0253  |   17.2667  |   16.7193   |   16.9993  |    16.9993  |    8.1603e+07  |\n",
      "| 75%          | nan        |  122.325   |  126.675   |  119.958    |  123.39    |   123.39    |    1.23275e+08 |\n",
      "| max          | nan        |  411.47    |  414.497   |  405.667    |  409.97    |   409.97    |    9.14082e+08 |\n",
      "| 1st_row      | 2010-06-29 |    1.26667 |    1.66667 |    1.16933  |    1.59267 |     1.59267 |    2.81494e+08 |\n",
      "| 2nd_row      | 2010-06-30 |    1.71933 |    2.028   |    1.55333  |    1.58867 |     1.58867 |    2.57806e+08 |\n",
      "| 2nd_last_row | 2024-02-01 |  188.5     |  189.88    |  184.28     |  188.86    |   188.86    |    9.18433e+07 |\n",
      "| last_row     | 2024-02-02 |  185.04    |  188.69    |  182        |  187.91    |   187.91    |    1.10505e+08 |\n",
      "\n",
      "Please note that python_repl_ast cannot use df_decribe, but can use df.\n",
      "\n",
      "Begin!\n",
      "Question: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "df_describe_str = str(df_describe.to_markdown())#json.dumps((df_describe.to_json())).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "partial_format = SUFFIX_WITH_DF_DESCRIBE.format(df_describe=df_describe_str)\n",
    "SUFFIX_FINAL = partial_format.replace(\"{{input}}\", \"{input}\").replace(\"{{agent_scratchpad}}\", \"{agent_scratchpad}\")\n",
    "print(SUFFIX_FINAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442f4e0",
   "metadata": {},
   "source": [
    "Now, let's use a workaround for the Langchain bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b58f2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\")\n",
    "\n",
    "#Bug 1 workaround: the stop token in the React Agent is \\nObservation, but needs to be \\nFinal Answer for Pandas agent\n",
    "llm_with_stop = llm.bind(stop=[\"\\nFinal Answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "76425aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bug 2 workaround:\n",
    "agent = create_pandas_dataframe_agent(llm_with_stop, tsla_stock, include_df_in_prompt = None, #handle_parsing_errors=True,\n",
    "                                      agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, prefix=PREFIX, suffix=SUFFIX_FINAL, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "01ba8049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The most recent close price for TSLA can be found in the 'Close' column of the last row of the dataframe `df`.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Close'].iloc[-1]\u001b[0m\u001b[36;1m\u001b[1;3m187.910004\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The most recent close price for TSLA was $187.91.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What was the most recent close price for TSLA?', 'output': 'The most recent close price for TSLA was $187.91.'}\n"
     ]
    }
   ],
   "source": [
    "response = try_agent(agent, \"What was the most recent close price for TSLA?\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f09fa36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer this question, I need to compare the standard deviation of the 'Open' prices with the standard deviation of the 'Close' prices.\n",
      "\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Open'].std(), df['Close'].std()\u001b[0m\u001b[36;1m\u001b[1;3m(101.91593442111841, 101.82818449060503)\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The 'Open' prices have a slightly larger standard deviation than the 'Close' prices.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Does the change in open or close prices have a larger standard deviation?', 'output': \"The 'Open' prices have a slightly larger standard deviation than the 'Close' prices.\"}\n"
     ]
    }
   ],
   "source": [
    "response = try_agent(agent, \"Does the change in open or close prices have a larger standard deviation?\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd7e88",
   "metadata": {},
   "source": [
    "That failed to take the difference and I had to significantly change the PREFIX and SUFFIX to get it to sometimes work. We can take a look at the Langchain code again, but let's move on.\n",
    "\n",
    "#### Let's now try the OPENAI_FUNCTIONS agent in Langchain\n",
    "\n",
    "**Note:** This works very badly with \"gpt-4-1106-preview\", but a bit better with \"gpt-4\" and \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bf0edd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "agent = create_pandas_dataframe_agent(llm, tsla_stock,verbose=True,agent_type=AgentType.OPENAI_FUNCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "62af7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Close'].iloc[-1]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m187.910004\u001b[0m\u001b[32;1m\u001b[1;3mThe most recent close price for TSLA was $187.91.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What was the most recent close price for TSLA?', 'output': 'The most recent close price for TSLA was $187.91.'}\n"
     ]
    }
   ],
   "source": [
    "response = try_agent(agent, \"What was the most recent close price for TSLA?\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b20d9e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df['Open'].diff().std(), df['Close'].diff().std()\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m(4.945367157862929, 4.678933840976249)\u001b[0m\u001b[32;1m\u001b[1;3mThe standard deviation of the change in open prices is larger than the standard deviation of the change in close prices.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Does the change in open or close prices have a larger standard deviation?', 'output': 'The standard deviation of the change in open prices is larger than the standard deviation of the change in close prices.'}\n"
     ]
    }
   ],
   "source": [
    "response = try_agent(agent, \"Does the change in open or close prices have a larger standard deviation?\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb03cef",
   "metadata": {},
   "source": [
    "Let's forget about Langchain Agents for now as it is a little bit of a pain ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311570a4",
   "metadata": {},
   "source": [
    "### Let's try Agents with [Pandas AI](https://docs.pandas-ai.com/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aced466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasai import SmartDatalake\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "from pandasai import Agent\n",
    "from pandasai.skills import skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13bfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4-1106-preview\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdcb74",
   "metadata": {},
   "source": [
    "Let's first just use the simple agent with SmartDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d92389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Close prices have a larger standard deviation.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = SmartDataframe(tsla_stock, description =\"TSLA Stock Market Data\", config={\"llm\": llm})\n",
    "agent.chat(\"Does the change in open or close prices have a larger standard deviation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0591b4",
   "metadata": {},
   "source": [
    "That actually did not work at all - looking at the log below shows it just made up the answer.\n",
    "\n",
    "Let's show something a bit more interesting using the Agent framework from Pandas-AI which allows us to directly inform our LLM or \"skills\" we added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7d9a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function doc string to give more context to the model for use this skill\n",
    "@skill\n",
    "def get_capm_params(stock_data: pd.DataFrame, benchmark_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function estimates an Intercept(alpha) and a beta by regressing the stock returns on the benchmark returns.\n",
    "    This is the Capital Asset Pricing Model (CAPM) model.\n",
    "    Args:\n",
    "        stock_data: A Pandas DataFrame with stock data\n",
    "        benchmark_data: A Pandas DataFrame with the benchmark's data\n",
    "    Returns:\n",
    "        alpha: Intercept\n",
    "        beta: Beta\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import pandas as pd\n",
    "    #calculate stock returns\n",
    "    stock_data['Return'] = stock_data['Close'].pct_change()\n",
    "    stock_data.dropna(inplace=True)\n",
    "    #calculate benchmark returns\n",
    "    benchmark_data['Return'] = benchmark_data['Close'].pct_change()\n",
    "    benchmark_data.dropna(inplace=True)\n",
    "    #perform inner join to get common dates\n",
    "    stock_data = stock_data.merge(benchmark_data, on='Date', how='inner', suffixes=('_stock', '_benchmark'))\n",
    "    X = stock_data[['Return_benchmark']]\n",
    "    y = stock_data['Return_stock']\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    alpha = model.intercept_\n",
    "    beta = model.coef_[0]\n",
    "    return alpha, beta\n",
    "\n",
    "agent = Agent([tsla_stock, spy_etf], config={\"llm\": llm}, memory_size=10, description=\"A list of 2 DataFrames: TSLA stock data and SPY ETF data respectively.\")\n",
    "\n",
    "agent.add_skills(get_capm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2ae4aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0013747603371657858, 1.4142763404820184)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_capm_params(tsla_stock, spy_etf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4346f52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4098669332856566\n"
     ]
    }
   ],
   "source": [
    "# Chat with the agent\n",
    "response = agent.chat(\"What is the Beta of TSLA? You can use the SPY ETF as the benchmark and use the CAPM model.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a923e2b",
   "metadata": {},
   "source": [
    "We got the right answer, but the beta is slightly different - let's check the logs ... \n",
    "\n",
    "This appears to just be estimation sensitivity so all good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f790034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print pandasai.log file to see the logs\n",
    "# with open(\"pandasai.log\", \"r\") as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540a719",
   "metadata": {},
   "source": [
    "This seems promising! So far we have just shown pretty simple agents and can satisfy requirements as long as the users can read the code and understand all he intermediate steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fae04e",
   "metadata": {},
   "source": [
    "#### SQL Agent - WORK IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7996f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, Float, String, DateTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abbe5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///tsla_stock.db')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5994ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.169333</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>1.592667</td>\n",
       "      <td>281494500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>1.719333</td>\n",
       "      <td>2.028000</td>\n",
       "      <td>1.553333</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>1.588667</td>\n",
       "      <td>257806500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.728000</td>\n",
       "      <td>1.351333</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>123282000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>1.247333</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>77097000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>1.074000</td>\n",
       "      <td>1.074000</td>\n",
       "      <td>103003500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
       "0  2010-06-29  1.266667  1.666667  1.169333  1.592667   1.592667  281494500   \n",
       "1  2010-06-30  1.719333  2.028000  1.553333  1.588667   1.588667  257806500   \n",
       "2  2010-07-01  1.666667  1.728000  1.351333  1.464000   1.464000  123282000   \n",
       "3  2010-07-02  1.533333  1.540000  1.247333  1.280000   1.280000   77097000   \n",
       "4  2010-07-06  1.333333  1.333333  1.055333  1.074000   1.074000  103003500   \n",
       "\n",
       "  Symbol  \n",
       "0   TSLA  \n",
       "1   TSLA  \n",
       "2   TSLA  \n",
       "3   TSLA  \n",
       "4   TSLA  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_stock['Symbol'] = 'TSLA'\n",
    "tsla_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d3ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQLAlchemy to define a table schema\n",
    "metadata = MetaData()\n",
    "\n",
    "stocks = Table('stocks', metadata,\n",
    "    Column('Symbol', String, comment='Stock symbol'),\n",
    "    Column('Date', DateTime, comment='Date of trading'),\n",
    "    Column('Open', Float, comment='Opening price'),\n",
    "    Column('High', Float, comment='Highest price during the trading day'),\n",
    "    Column('Low', Float, comment='Lowest price during the trading day'),\n",
    "    Column('Close', Float, comment='Closing price at the end of trading day'),\n",
    "    Column('Adj Close', Float, comment='Adjusted closing price'),\n",
    "    Column('Volume', Integer, comment='Number of shares traded'),\n",
    ")\n",
    "metadata.create_all(engine)  # Creates the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87d6740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3423"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_stock.to_sql('stocks', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4667e921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### In sqlite3 comments are not accessible so we will add a table to store column descriptions\n",
    "descriptions = {\n",
    "    'Column': ['Symbol', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'],\n",
    "    'Description': [\n",
    "        'Stock symbol', 'Date of trading', 'Opening price', 'Highest price during the trading day',\n",
    "        'Lowest price during the trading day', 'Closing price at the end of trading day',\n",
    "        'Adjusted closing price', 'Number of shares traded'\n",
    "    ]\n",
    "}\n",
    "desc_df = pd.DataFrame(descriptions)\n",
    "desc_df['Table'] = 'stocks'\n",
    "desc_df[['Table','Column','Description']].to_sql('column_descriptions', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87b3ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
      "0  2010-06-29  1.266667  1.666667  1.169333  1.592667   1.592667  281494500   \n",
      "1  2010-06-30  1.719333  2.028000  1.553333  1.588667   1.588667  257806500   \n",
      "\n",
      "  Symbol  \n",
      "0   TSLA  \n",
      "1   TSLA  \n",
      "    Table     Column                              Description\n",
      "0  stocks     Symbol                             Stock symbol\n",
      "1  stocks       Date                          Date of trading\n",
      "2  stocks       Open                            Opening price\n",
      "3  stocks       High     Highest price during the trading day\n",
      "4  stocks        Low      Lowest price during the trading day\n",
      "5  stocks      Close  Closing price at the end of trading day\n",
      "6  stocks  Adj Close                   Adjusted closing price\n",
      "7  stocks     Volume                  Number of shares traded\n"
     ]
    }
   ],
   "source": [
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('tsla_stock.db')\n",
    "\n",
    "# Define your SQL query\n",
    "query = \"SELECT * FROM stocks\"\n",
    "\n",
    "# Use pandas to execute the query and load the result into a DataFrame\n",
    "try:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(df.head(2))\n",
    "    descriptions = pd.read_sql_query(\"SELECT * FROM column_descriptions\", conn)\n",
    "    print(descriptions)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5782658",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_SYSTEM_PROMPT = \"\"\"\"\n",
    "You are a sophisticated generative AI trained to understand human language queries about stock market data and translate them into SQL queries. The database you are querying contains a table named stocks with the following columns:\n",
    "\n",
    "Symbol: The stock symbol.\n",
    "Date: The date of the trading activity.\n",
    "Open: The opening price of the stock on that day.\n",
    "High: The highest price of the stock during the trading day.\n",
    "Low: The lowest price of the stock during the trading day.\n",
    "Close: The closing price of the stock at the end of the trading day.\n",
    "Adj Close: The adjusted closing price after accounting for any corporate actions.\n",
    "Volume: The number of shares traded during the day.\n",
    "Tasks:\n",
    "\n",
    "Convert the human language query into a precise SQL query.\n",
    "Ensure to accurately interpret the key details from the human query such as specific dates, stock symbols, price ranges, and other relevant filters.\n",
    "Your responses should strictly be SQL queries; do not execute them.\n",
    "Examples:\n",
    "\n",
    "Human Query: \"Show me all transactions of AAPL stocks from January 2021.\"\n",
    "AI Response:\n",
    "```sql\n",
    "SELECT * FROM stocks WHERE Symbol = 'AAPL' AND Date >= '2021-01-01' AND Date < '2022-01-01';\n",
    "```\n",
    "Human Query: \"What was the highest price of MSFT in the last year?\"\n",
    "AI Response:\n",
    "```sql\n",
    "SELECT MAX(High) FROM stocks WHERE Symbol = 'MSFT' AND Date >= date('now', '-1 year');\n",
    "```\n",
    "Human Query: \"List all closing prices below $50 for any stock last month.\"\n",
    "AI Response:\n",
    "```sql\n",
    "Copy code\n",
    "SELECT Symbol, Date, Close FROM stocks WHERE Close < 50 AND Date >= date('now', 'start of month', '-1 month') AND Date < date('now', 'start of month');\n",
    "```\n",
    "Instructions:\n",
    "\n",
    "Always validate the input query to ensure clarity and completeness.\n",
    "Extract relevant temporal and financial parameters from the query.\n",
    "Construct SQL queries that are syntactically correct and formatted for readability.\n",
    "Assume the queries are to be executed in a SQLite database environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5271ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| Table   | Column    | Description                             |\\n|:--------|:----------|:----------------------------------------|\\n| stocks  | Symbol    | Stock symbol                            |\\n| stocks  | Date      | Date of trading                         |\\n| stocks  | Open      | Opening price                           |\\n| stocks  | High      | Highest price during the trading day    |\\n| stocks  | Low       | Lowest price during the trading day     |\\n| stocks  | Close     | Closing price at the end of trading day |\\n| stocks  | Adj Close | Adjusted closing price                  |\\n| stocks  | Volume    | Number of shares traded                 |'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions.to_markdown(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02cb6943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a sophisticated generative AI model designed to convert human language queries into SQL queries. Your operation is based on a dynamic understanding of database schemas through a descriptions table. This descriptions table stores metadata about tables and columns in the database and includes the following columns:\n",
      "\n",
      "Table: The name of the table to which the description relates.\n",
      "Column: The actual column name in the table.\n",
      "Description: A human-readable description of what the column represents.\n",
      "\n",
      "**Example Description Table:**\n",
      "| Table   | Column    | Description                             |\n",
      "|:--------|:----------|:----------------------------------------|\n",
      "| stocks  | Symbol    | Stock symbol                            |\n",
      "| stocks  | Date      | Date of trading                         |\n",
      "| stocks  | Open      | Opening price                           |\n",
      "| stocks  | High      | Highest price during the trading day    |\n",
      "| stocks  | Low       | Lowest price during the trading day     |\n",
      "| stocks  | Close     | Closing price at the end of trading day |\n",
      "| stocks  | Adj Close | Adjusted closing price                  |\n",
      "| stocks  | Volume    | Number of shares traded                 |\n",
      "\n",
      "Tasks:\n",
      "Convert the human language query into a precise SQL query.\n",
      "Ensure to accurately interpret the key details from the human query such as specific dates and other relevant filters.\n",
      "Your responses should strictly be SQL queries; do not execute them.\n",
      "\n",
      "SQL Response examples using the example descriptions table:\n",
      "Human Query: \"Show me all transactions of AAPL stocks from January 2021.\"\n",
      "AI Response:\n",
      "```sql\n",
      "SELECT * FROM stocks WHERE Symbol = 'AAPL' AND Date >= '2021-01-01' AND Date < '2022-01-01';\n",
      "```\n",
      "Human Query: \"What was the highest price of MSFT in the last year?\"\n",
      "AI Response:\n",
      "```sql\n",
      "SELECT MAX(High) FROM stocks WHERE Symbol = 'MSFT' AND Date >= date('now', '-1 year');\n",
      "```\n",
      "Human Query: \"List all closing prices below $50 for any stock last month.\"\n",
      "AI Response:\n",
      "```sql\n",
      "SELECT Symbol, Date, Close FROM stocks WHERE Close < 50 AND Date >= date('now', 'start of month', '-1 month') AND Date < date('now', 'start of month');\n",
      "```\n",
      "\n",
      "Now it's your turn to generate SQL queries based on the provided human language queries.\n",
      "\n",
      "Description Table:\n",
      "| Table   | Column    | Description                             |\n",
      "|:--------|:----------|:----------------------------------------|\n",
      "| stocks  | Symbol    | Stock symbol                            |\n",
      "| stocks  | Date      | Date of trading                         |\n",
      "| stocks  | Open      | Opening price                           |\n",
      "| stocks  | High      | Highest price during the trading day    |\n",
      "| stocks  | Low       | Lowest price during the trading day     |\n",
      "| stocks  | Close     | Closing price at the end of trading day |\n",
      "| stocks  | Adj Close | Adjusted closing price                  |\n",
      "| stocks  | Volume    | Number of shares traded                 |\n",
      "\n",
      "Instructions:\n",
      "\n",
      "Utilize the descriptions in the descriptions table to map human-language queries to appropriate SQL queries.\n",
      "Pay careful attention to interpreting the temporal parameters specified in queries.\n",
      "Generate SQL queries that are syntactically correct, ensuring they reflect the semantic understanding of the database structure based on descriptions.\n",
      "Operate under the assumption that the database environment supports typical SQL functions and date calculations.\n",
      "Remember to use quotes for column names that include a space when generating SQL queries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_SYSTEM_PROMPT2 = \"\"\"\n",
    "You are a sophisticated generative AI model designed to convert human language queries into SQL queries. Your operation is based on a dynamic understanding of database schemas through a descriptions table. This descriptions table stores metadata about tables and columns in the database and includes the following columns:\n",
    "\n",
    "Table: The name of the table to which the description relates.\n",
    "Column: The actual column name in the table.\n",
    "Description: A human-readable description of what the column represents.\n",
    "\n",
    "**Example Description Table:**\n",
    "| Table   | Column    | Description                             |\n",
    "|:--------|:----------|:----------------------------------------|\n",
    "| stocks  | Symbol    | Stock symbol                            |\n",
    "| stocks  | Date      | Date of trading                         |\n",
    "| stocks  | Open      | Opening price                           |\n",
    "| stocks  | High      | Highest price during the trading day    |\n",
    "| stocks  | Low       | Lowest price during the trading day     |\n",
    "| stocks  | Close     | Closing price at the end of trading day |\n",
    "| stocks  | Adj Close | Adjusted closing price                  |\n",
    "| stocks  | Volume    | Number of shares traded                 |\n",
    "\n",
    "Tasks:\n",
    "Convert the human language query into a precise SQL query.\n",
    "Ensure to accurately interpret the key details from the human query such as specific dates and other relevant filters.\n",
    "Your responses should strictly be SQL queries; do not execute them.\n",
    "\n",
    "SQL Response examples using the example descriptions table:\n",
    "Human Query: \"Show me all transactions of AAPL stocks from January 2021.\"\n",
    "AI Response:\n",
    "```sql\n",
    "SELECT * FROM stocks WHERE Symbol = 'AAPL' AND Date >= '2021-01-01' AND Date < '2022-01-01';\n",
    "```\n",
    "Human Query: \"What was the highest price of MSFT in the last year?\"\n",
    "AI Response:\n",
    "```sql\n",
    "SELECT MAX(High) FROM stocks WHERE Symbol = 'MSFT' AND Date >= date('now', '-1 year');\n",
    "```\n",
    "Human Query: \"List all closing prices below $50 for any stock last month.\"\n",
    "AI Response:\n",
    "```sql\n",
    "SELECT Symbol, Date, Close FROM stocks WHERE Close < 50 AND Date >= date('now', 'start of month', '-1 month') AND Date < date('now', 'start of month');\n",
    "```\n",
    "\n",
    "Now it's your turn to generate SQL queries based on the provided human language queries.\n",
    "\n",
    "Description Table:\n",
    "{descriptions_table}\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Utilize the descriptions in the descriptions table to map human-language queries to appropriate SQL queries.\n",
    "Pay careful attention to interpreting the temporal parameters specified in queries.\n",
    "Generate SQL queries that are syntactically correct, ensuring they reflect the semantic understanding of the database structure based on descriptions.\n",
    "Operate under the assumption that the database environment supports typical SQL functions and date calculations.\n",
    "Remember to use quotes for column names that include a space when generating SQL queries.\n",
    "\"\"\"\n",
    "\n",
    "SQL_SYSTEM_PROMPT2 = SQL_SYSTEM_PROMPT2.format(descriptions_table=descriptions.to_markdown(index=False))\n",
    "print(SQL_SYSTEM_PROMPT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1aa04446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT MAX(High) FROM stocks WHERE Symbol = 'TSLA' AND Date >= date('now', '-1 year');\n",
      "```\n",
      "[['MAX(High)'], (299.290009,)]\n"
     ]
    }
   ],
   "source": [
    "response_full = openai.chat.completions.create(model=\"gpt-4o\", messages=[{\"role\": \"system\", \"content\": SQL_SYSTEM_PROMPT2},\n",
    "                                                                      {\"role\": \"user\", \"content\": \"What was the highest price of TSLA in the last year?\" }],\n",
    "                                                                      temperature=0) #, logprobs=True, top_logprobs=5\n",
    "\n",
    "print(response_full.choices[0].message.content)\n",
    "\n",
    "#extract the SQL query from the response\n",
    "sql_query = response_full.choices[0].message.content.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "#run the sql query using the conn connection \n",
    "conn = sqlite3.connect('tsla_stock.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Get column names from cursor.description\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "result = cursor.fetchall()\n",
    "result_with_column_names = [column_names] + result\n",
    "\n",
    "print(result_with_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58ecb234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT AVG(High) FROM stocks WHERE Symbol = 'TSLA' AND Date >= '2023-12-01' AND Date < '2024-01-01';\n",
      "```\n",
      "[['AVG(High)'], (251.22250119999998,)]\n"
     ]
    }
   ],
   "source": [
    "response_full = openai.chat.completions.create(model=\"gpt-4o\", messages=[{\"role\": \"system\", \"content\": SQL_SYSTEM_PROMPT2},\n",
    "                                                                      {\"role\": \"user\", \"content\": \"What was the average daily high price of TSLA in December 2023?\" }],\n",
    "                                                                      temperature=0) #, logprobs=True, top_logprobs=5\n",
    "\n",
    "print(response_full.choices[0].message.content)\n",
    "\n",
    "#extract the SQL query from the response\n",
    "sql_query = response_full.choices[0].message.content.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "#run the sql query using the conn connection \n",
    "conn = sqlite3.connect('tsla_stock.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Get column names from cursor.description\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "result = cursor.fetchall()\n",
    "result_with_column_names = [column_names] + result\n",
    "\n",
    "print(result_with_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f311a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT * FROM stocks WHERE Symbol = 'TSLA' AND Date >= '2024-01-01' AND Date < '2024-02-01';\n",
      "```\n",
      "[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Symbol'], ('2024-01-02', 250.080002, 251.25, 244.410004, 248.419998, 248.419998, 104654200, 'TSLA'), ('2024-01-03', 244.979996, 245.679993, 236.320007, 238.449997, 238.449997, 121082600, 'TSLA'), ('2024-01-04', 239.25, 242.699997, 237.729996, 237.929993, 237.929993, 102629300, 'TSLA'), ('2024-01-05', 236.860001, 240.119995, 234.899994, 237.490005, 237.490005, 92379400, 'TSLA'), ('2024-01-08', 236.139999, 241.25, 235.300003, 240.449997, 240.449997, 85166600, 'TSLA'), ('2024-01-09', 238.110001, 238.960007, 232.039993, 234.960007, 234.960007, 96705700, 'TSLA'), ('2024-01-10', 235.100006, 235.5, 231.289993, 233.940002, 233.940002, 91628500, 'TSLA'), ('2024-01-11', 230.570007, 230.929993, 225.369995, 227.220001, 227.220001, 105873600, 'TSLA'), ('2024-01-12', 220.080002, 225.339996, 217.149994, 218.889999, 218.889999, 122889000, 'TSLA'), ('2024-01-16', 215.100006, 223.490005, 212.179993, 219.910004, 219.910004, 115355000, 'TSLA'), ('2024-01-17', 214.860001, 215.669998, 212.009995, 215.550003, 215.550003, 103164400, 'TSLA'), ('2024-01-18', 216.880005, 217.449997, 208.740005, 211.880005, 211.880005, 108595400, 'TSLA'), ('2024-01-19', 209.990005, 213.190002, 207.559998, 212.190002, 212.190002, 102095800, 'TSLA'), ('2024-01-22', 212.259995, 217.800003, 206.270004, 208.800003, 208.800003, 117952500, 'TSLA'), ('2024-01-23', 211.300003, 215.649994, 207.75, 209.139999, 209.139999, 106605900, 'TSLA'), ('2024-01-24', 211.880005, 212.729996, 206.770004, 207.830002, 207.830002, 123369900, 'TSLA'), ('2024-01-25', 189.699997, 193.0, 180.059998, 182.630005, 182.630005, 198076800, 'TSLA'), ('2024-01-26', 185.5, 186.779999, 182.100006, 183.25, 183.25, 107343200, 'TSLA'), ('2024-01-29', 185.630005, 191.479996, 183.669998, 190.929993, 190.929993, 125013100, 'TSLA'), ('2024-01-30', 195.330002, 196.360001, 190.610001, 191.589996, 191.589996, 109982300, 'TSLA'), ('2024-01-31', 187.0, 193.970001, 185.850006, 187.289993, 187.289993, 103221400, 'TSLA')]\n"
     ]
    }
   ],
   "source": [
    "response_full = openai.chat.completions.create(model=\"gpt-4o\", messages=[{\"role\": \"system\", \"content\": SQL_SYSTEM_PROMPT2},\n",
    "                                                                      {\"role\": \"user\", \"content\": \"Show me all trade data for TSLA stocks from January 2024.\" }],\n",
    "                                                                      temperature=0) #, logprobs=True, top_logprobs=5\n",
    "\n",
    "print(response_full.choices[0].message.content)\n",
    "\n",
    "#extract the SQL query from the response\n",
    "sql_query = response_full.choices[0].message.content.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "#run the sql query using the conn connection \n",
    "conn = sqlite3.connect('tsla_stock.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Get column names from cursor.description\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "result = cursor.fetchall()\n",
    "result_with_column_names = [column_names] + result\n",
    "print(result_with_column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8964bdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>250.080002</td>\n",
       "      <td>251.250000</td>\n",
       "      <td>244.410004</td>\n",
       "      <td>248.419998</td>\n",
       "      <td>248.419998</td>\n",
       "      <td>104654200</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>244.979996</td>\n",
       "      <td>245.679993</td>\n",
       "      <td>236.320007</td>\n",
       "      <td>238.449997</td>\n",
       "      <td>238.449997</td>\n",
       "      <td>121082600</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>239.250000</td>\n",
       "      <td>242.699997</td>\n",
       "      <td>237.729996</td>\n",
       "      <td>237.929993</td>\n",
       "      <td>237.929993</td>\n",
       "      <td>102629300</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>236.860001</td>\n",
       "      <td>240.119995</td>\n",
       "      <td>234.899994</td>\n",
       "      <td>237.490005</td>\n",
       "      <td>237.490005</td>\n",
       "      <td>92379400</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>236.139999</td>\n",
       "      <td>241.250000</td>\n",
       "      <td>235.300003</td>\n",
       "      <td>240.449997</td>\n",
       "      <td>240.449997</td>\n",
       "      <td>85166600</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-09</td>\n",
       "      <td>238.110001</td>\n",
       "      <td>238.960007</td>\n",
       "      <td>232.039993</td>\n",
       "      <td>234.960007</td>\n",
       "      <td>234.960007</td>\n",
       "      <td>96705700</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>235.100006</td>\n",
       "      <td>235.500000</td>\n",
       "      <td>231.289993</td>\n",
       "      <td>233.940002</td>\n",
       "      <td>233.940002</td>\n",
       "      <td>91628500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>230.570007</td>\n",
       "      <td>230.929993</td>\n",
       "      <td>225.369995</td>\n",
       "      <td>227.220001</td>\n",
       "      <td>227.220001</td>\n",
       "      <td>105873600</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>220.080002</td>\n",
       "      <td>225.339996</td>\n",
       "      <td>217.149994</td>\n",
       "      <td>218.889999</td>\n",
       "      <td>218.889999</td>\n",
       "      <td>122889000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>215.100006</td>\n",
       "      <td>223.490005</td>\n",
       "      <td>212.179993</td>\n",
       "      <td>219.910004</td>\n",
       "      <td>219.910004</td>\n",
       "      <td>115355000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>214.860001</td>\n",
       "      <td>215.669998</td>\n",
       "      <td>212.009995</td>\n",
       "      <td>215.550003</td>\n",
       "      <td>215.550003</td>\n",
       "      <td>103164400</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>216.880005</td>\n",
       "      <td>217.449997</td>\n",
       "      <td>208.740005</td>\n",
       "      <td>211.880005</td>\n",
       "      <td>211.880005</td>\n",
       "      <td>108595400</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>209.990005</td>\n",
       "      <td>213.190002</td>\n",
       "      <td>207.559998</td>\n",
       "      <td>212.190002</td>\n",
       "      <td>212.190002</td>\n",
       "      <td>102095800</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>212.259995</td>\n",
       "      <td>217.800003</td>\n",
       "      <td>206.270004</td>\n",
       "      <td>208.800003</td>\n",
       "      <td>208.800003</td>\n",
       "      <td>117952500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>211.300003</td>\n",
       "      <td>215.649994</td>\n",
       "      <td>207.750000</td>\n",
       "      <td>209.139999</td>\n",
       "      <td>209.139999</td>\n",
       "      <td>106605900</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-01-24</td>\n",
       "      <td>211.880005</td>\n",
       "      <td>212.729996</td>\n",
       "      <td>206.770004</td>\n",
       "      <td>207.830002</td>\n",
       "      <td>207.830002</td>\n",
       "      <td>123369900</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>189.699997</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>180.059998</td>\n",
       "      <td>182.630005</td>\n",
       "      <td>182.630005</td>\n",
       "      <td>198076800</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>185.500000</td>\n",
       "      <td>186.779999</td>\n",
       "      <td>182.100006</td>\n",
       "      <td>183.250000</td>\n",
       "      <td>183.250000</td>\n",
       "      <td>107343200</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-01-29</td>\n",
       "      <td>185.630005</td>\n",
       "      <td>191.479996</td>\n",
       "      <td>183.669998</td>\n",
       "      <td>190.929993</td>\n",
       "      <td>190.929993</td>\n",
       "      <td>125013100</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>195.330002</td>\n",
       "      <td>196.360001</td>\n",
       "      <td>190.610001</td>\n",
       "      <td>191.589996</td>\n",
       "      <td>191.589996</td>\n",
       "      <td>109982300</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>193.970001</td>\n",
       "      <td>185.850006</td>\n",
       "      <td>187.289993</td>\n",
       "      <td>187.289993</td>\n",
       "      <td>103221400</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "0   2024-01-02  250.080002  251.250000  244.410004  248.419998  248.419998   \n",
       "1   2024-01-03  244.979996  245.679993  236.320007  238.449997  238.449997   \n",
       "2   2024-01-04  239.250000  242.699997  237.729996  237.929993  237.929993   \n",
       "3   2024-01-05  236.860001  240.119995  234.899994  237.490005  237.490005   \n",
       "4   2024-01-08  236.139999  241.250000  235.300003  240.449997  240.449997   \n",
       "5   2024-01-09  238.110001  238.960007  232.039993  234.960007  234.960007   \n",
       "6   2024-01-10  235.100006  235.500000  231.289993  233.940002  233.940002   \n",
       "7   2024-01-11  230.570007  230.929993  225.369995  227.220001  227.220001   \n",
       "8   2024-01-12  220.080002  225.339996  217.149994  218.889999  218.889999   \n",
       "9   2024-01-16  215.100006  223.490005  212.179993  219.910004  219.910004   \n",
       "10  2024-01-17  214.860001  215.669998  212.009995  215.550003  215.550003   \n",
       "11  2024-01-18  216.880005  217.449997  208.740005  211.880005  211.880005   \n",
       "12  2024-01-19  209.990005  213.190002  207.559998  212.190002  212.190002   \n",
       "13  2024-01-22  212.259995  217.800003  206.270004  208.800003  208.800003   \n",
       "14  2024-01-23  211.300003  215.649994  207.750000  209.139999  209.139999   \n",
       "15  2024-01-24  211.880005  212.729996  206.770004  207.830002  207.830002   \n",
       "16  2024-01-25  189.699997  193.000000  180.059998  182.630005  182.630005   \n",
       "17  2024-01-26  185.500000  186.779999  182.100006  183.250000  183.250000   \n",
       "18  2024-01-29  185.630005  191.479996  183.669998  190.929993  190.929993   \n",
       "19  2024-01-30  195.330002  196.360001  190.610001  191.589996  191.589996   \n",
       "20  2024-01-31  187.000000  193.970001  185.850006  187.289993  187.289993   \n",
       "\n",
       "       Volume Symbol  \n",
       "0   104654200   TSLA  \n",
       "1   121082600   TSLA  \n",
       "2   102629300   TSLA  \n",
       "3    92379400   TSLA  \n",
       "4    85166600   TSLA  \n",
       "5    96705700   TSLA  \n",
       "6    91628500   TSLA  \n",
       "7   105873600   TSLA  \n",
       "8   122889000   TSLA  \n",
       "9   115355000   TSLA  \n",
       "10  103164400   TSLA  \n",
       "11  108595400   TSLA  \n",
       "12  102095800   TSLA  \n",
       "13  117952500   TSLA  \n",
       "14  106605900   TSLA  \n",
       "15  123369900   TSLA  \n",
       "16  198076800   TSLA  \n",
       "17  107343200   TSLA  \n",
       "18  125013100   TSLA  \n",
       "19  109982300   TSLA  \n",
       "20  103221400   TSLA  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result, columns=column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6bd97caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT Date, Open, High, Low, Close, \"Adj Close\"\n",
      "FROM stocks\n",
      "WHERE Symbol = 'TSLA' AND Date >= date('now', '-1 year')\n",
      "ORDER BY Date;\n",
      "```\n",
      "[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close'], ('2023-05-15', 167.660004, 169.759995, 164.550003, 166.350006, 166.350006), ('2023-05-16', 165.649994, 169.520004, 164.350006, 166.520004, 166.520004), ('2023-05-17', 168.410004, 174.5, 167.190002, 173.860001, 173.860001), ('2023-05-18', 174.220001, 177.059998, 172.449997, 176.889999, 176.889999), ('2023-05-19', 177.169998, 181.949997, 176.309998, 180.139999, 180.139999), ('2023-05-22', 180.699997, 189.320007, 180.110001, 188.869995, 188.869995), ('2023-05-23', 186.199997, 192.960007, 185.259995, 185.770004, 185.770004), ('2023-05-24', 182.229996, 184.220001, 178.220001, 182.899994, 182.899994), ('2023-05-25', 186.539993, 186.779999, 180.580002, 184.470001, 184.470001), ('2023-05-26', 184.619995, 198.600006, 184.529999, 193.169998, 193.169998), ('2023-05-30', 200.100006, 204.479996, 197.529999, 201.160004, 201.160004), ('2023-05-31', 199.779999, 203.949997, 195.119995, 203.929993, 203.929993), ('2023-06-01', 202.589996, 209.800003, 199.369995, 207.520004, 207.520004), ('2023-06-02', 210.149994, 217.25, 209.75, 213.970001, 213.970001), ('2023-06-05', 217.800003, 221.289993, 214.520004, 217.610001, 217.610001), ('2023-06-06', 216.139999, 221.910004, 212.529999, 221.309998, 221.309998), ('2023-06-07', 228.0, 230.830002, 223.199997, 224.570007, 224.570007), ('2023-06-08', 224.220001, 235.229996, 223.009995, 234.860001, 234.860001), ('2023-06-09', 249.070007, 252.419998, 242.020004, 244.399994, 244.399994), ('2023-06-12', 247.940002, 250.970001, 244.589996, 249.830002, 249.830002), ('2023-06-13', 253.509995, 259.679993, 251.339996, 258.709991, 258.709991), ('2023-06-14', 260.170013, 261.570007, 250.5, 256.790009, 256.790009), ('2023-06-15', 248.399994, 258.950012, 247.289993, 255.899994, 255.899994), ('2023-06-16', 258.920013, 263.600006, 257.209991, 260.540009, 260.540009), ('2023-06-20', 261.5, 274.75, 261.119995, 274.450012, 274.450012), ('2023-06-21', 275.130005, 276.98999, 257.779999, 259.459991, 259.459991), ('2023-06-22', 250.770004, 265.0, 248.25, 264.609985, 264.609985), ('2023-06-23', 259.290009, 262.450012, 252.800003, 256.600006, 256.600006), ('2023-06-26', 250.070007, 258.369995, 240.699997, 241.050003, 241.050003), ('2023-06-27', 243.240005, 250.389999, 240.850006, 250.210007, 250.210007), ('2023-06-28', 249.699997, 259.880005, 248.889999, 256.23999, 256.23999), ('2023-06-29', 258.029999, 260.73999, 253.610001, 257.5, 257.5), ('2023-06-30', 260.600006, 264.450012, 259.890015, 261.769989, 261.769989), ('2023-07-03', 276.48999, 284.25, 275.109985, 279.820007, 279.820007), ('2023-07-05', 278.820007, 283.850006, 277.600006, 282.480011, 282.480011), ('2023-07-06', 278.089996, 279.970001, 272.880005, 276.540009, 276.540009), ('2023-07-07', 278.429993, 280.779999, 273.769989, 274.429993, 274.429993), ('2023-07-10', 276.470001, 277.519989, 265.100006, 269.609985, 269.609985), ('2023-07-11', 268.649994, 270.899994, 266.369995, 269.790009, 269.790009), ('2023-07-12', 276.329987, 276.519989, 271.459991, 271.98999, 271.98999), ('2023-07-13', 274.589996, 279.450012, 270.600006, 277.899994, 277.899994), ('2023-07-14', 277.01001, 285.299988, 276.309998, 281.380005, 281.380005), ('2023-07-17', 286.630005, 292.230011, 283.570007, 290.380005, 290.380005), ('2023-07-18', 290.149994, 295.26001, 286.01001, 293.339996, 293.339996), ('2023-07-19', 296.040009, 299.290009, 289.519989, 291.26001, 291.26001), ('2023-07-20', 279.559998, 280.929993, 261.200012, 262.899994, 262.899994), ('2023-07-21', 268.0, 268.0, 255.800003, 260.019989, 260.019989), ('2023-07-24', 255.850006, 269.850006, 254.119995, 269.059998, 269.059998), ('2023-07-25', 272.380005, 272.899994, 265.0, 265.279999, 265.279999), ('2023-07-26', 263.25, 268.040009, 261.75, 264.350006, 264.350006), ('2023-07-27', 268.309998, 269.130005, 255.300003, 255.710007, 255.710007), ('2023-07-28', 259.859985, 267.25, 258.230011, 266.440002, 266.440002), ('2023-07-31', 267.480011, 269.079987, 263.779999, 267.429993, 267.429993), ('2023-08-01', 266.26001, 266.470001, 260.25, 261.070007, 261.070007), ('2023-08-02', 255.570007, 259.519989, 250.490005, 254.110001, 254.110001), ('2023-08-03', 252.039993, 260.48999, 252.0, 259.320007, 259.320007), ('2023-08-04', 260.970001, 264.769989, 253.110001, 253.860001, 253.860001), ('2023-08-07', 251.449997, 253.649994, 242.759995, 251.449997, 251.449997), ('2023-08-08', 247.449997, 250.919998, 245.009995, 249.699997, 249.699997), ('2023-08-09', 250.869995, 251.100006, 241.899994, 242.190002, 242.190002), ('2023-08-10', 245.399994, 251.800003, 243.0, 245.339996, 245.339996), ('2023-08-11', 241.770004, 243.789993, 238.020004, 242.649994, 242.649994), ('2023-08-14', 235.699997, 240.660004, 233.75, 239.759995, 239.759995), ('2023-08-15', 238.729996, 240.5, 232.610001, 232.960007, 232.960007), ('2023-08-16', 228.020004, 233.970001, 225.380005, 225.600006, 225.600006), ('2023-08-17', 226.059998, 226.740005, 218.830002, 219.220001, 219.220001), ('2023-08-18', 214.119995, 217.580002, 212.360001, 215.490005, 215.490005), ('2023-08-21', 221.550003, 232.130005, 220.580002, 231.279999, 231.279999), ('2023-08-22', 240.25, 240.820007, 229.550003, 233.190002, 233.190002), ('2023-08-23', 229.339996, 238.979996, 229.289993, 236.860001, 236.860001), ('2023-08-24', 238.660004, 238.919998, 228.179993, 230.039993, 230.039993), ('2023-08-25', 231.309998, 239.0, 230.350006, 238.589996, 238.589996), ('2023-08-28', 242.580002, 244.380005, 235.350006, 238.820007, 238.820007), ('2023-08-29', 238.580002, 257.480011, 237.770004, 257.179993, 257.179993), ('2023-08-30', 254.199997, 260.51001, 250.589996, 256.899994, 256.899994), ('2023-08-31', 255.979996, 261.179993, 255.050003, 258.079987, 258.079987), ('2023-09-01', 257.26001, 259.079987, 242.009995, 245.009995, 245.009995), ('2023-09-05', 245.0, 258.0, 244.860001, 256.48999, 256.48999), ('2023-09-06', 255.139999, 255.389999, 245.059998, 251.919998, 251.919998), ('2023-09-07', 245.070007, 252.809998, 243.270004, 251.490005, 251.490005), ('2023-09-08', 251.220001, 256.519989, 246.669998, 248.5, 248.5), ('2023-09-11', 264.269989, 274.850006, 260.609985, 273.579987, 273.579987), ('2023-09-12', 270.76001, 278.390015, 266.600006, 267.480011, 267.480011), ('2023-09-13', 270.070007, 274.980011, 268.100006, 271.299988, 271.299988), ('2023-09-14', 271.320007, 276.709991, 270.420013, 276.040009, 276.040009), ('2023-09-15', 277.549988, 278.980011, 271.0, 274.390015, 274.390015), ('2023-09-18', 271.160004, 271.440002, 263.76001, 265.279999, 265.279999), ('2023-09-19', 264.350006, 267.850006, 261.200012, 266.5, 266.5), ('2023-09-20', 267.040009, 273.929993, 262.459991, 262.589996, 262.589996), ('2023-09-21', 257.850006, 260.859985, 254.210007, 255.699997, 255.699997), ('2023-09-22', 257.399994, 257.790009, 244.479996, 244.880005, 244.880005), ('2023-09-25', 243.380005, 247.100006, 238.309998, 246.990005, 246.990005), ('2023-09-26', 242.979996, 249.550003, 241.660004, 244.119995, 244.119995), ('2023-09-27', 244.259995, 245.330002, 234.580002, 240.5, 240.5), ('2023-09-28', 240.020004, 247.550003, 238.649994, 246.380005, 246.380005), ('2023-09-29', 250.0, 254.770004, 246.350006, 250.220001, 250.220001), ('2023-10-02', 244.809998, 254.279999, 242.619995, 251.600006, 251.600006), ('2023-10-03', 248.610001, 250.020004, 244.449997, 246.529999, 246.529999), ('2023-10-04', 248.139999, 261.859985, 247.600006, 261.160004, 261.160004), ('2023-10-05', 260.0, 263.600006, 256.25, 260.049988, 260.049988), ('2023-10-06', 253.979996, 261.649994, 250.649994, 260.529999, 260.529999), ('2023-10-09', 255.309998, 261.359985, 252.050003, 259.670013, 259.670013), ('2023-10-10', 257.75, 268.940002, 257.649994, 263.619995, 263.619995), ('2023-10-11', 266.200012, 268.600006, 260.899994, 262.98999, 262.98999), ('2023-10-12', 262.920013, 265.410004, 256.630005, 258.869995, 258.869995), ('2023-10-13', 258.899994, 259.600006, 250.220001, 251.119995, 251.119995), ('2023-10-16', 250.050003, 255.399994, 248.479996, 253.919998, 253.919998), ('2023-10-17', 250.100006, 257.179993, 247.080002, 254.850006, 254.850006), ('2023-10-18', 252.699997, 254.630005, 242.080002, 242.679993, 242.679993), ('2023-10-19', 225.949997, 230.610001, 216.779999, 220.110001, 220.110001), ('2023-10-20', 217.009995, 218.860001, 210.419998, 211.990005, 211.990005), ('2023-10-23', 210.0, 216.979996, 202.509995, 212.080002, 212.080002), ('2023-10-24', 216.5, 222.050003, 214.110001, 216.520004, 216.520004), ('2023-10-25', 215.880005, 220.100006, 212.199997, 212.419998, 212.419998), ('2023-10-26', 211.320007, 214.800003, 204.880005, 205.759995, 205.759995), ('2023-10-27', 210.600006, 212.410004, 205.770004, 207.300003, 207.300003), ('2023-10-30', 209.279999, 210.880005, 194.669998, 197.360001, 197.360001), ('2023-10-31', 196.119995, 202.800003, 194.070007, 200.839996, 200.839996), ('2023-11-01', 204.039993, 205.990005, 197.850006, 205.660004, 205.660004), ('2023-11-02', 212.970001, 219.199997, 211.449997, 218.509995, 218.509995), ('2023-11-03', 221.149994, 226.369995, 218.399994, 219.960007, 219.960007), ('2023-11-06', 223.979996, 226.320007, 215.0, 219.270004, 219.270004), ('2023-11-07', 219.979996, 223.119995, 215.720001, 222.179993, 222.179993), ('2023-11-08', 223.149994, 224.149994, 217.639999, 222.110001, 222.110001), ('2023-11-09', 219.75, 220.800003, 206.679993, 209.979996, 209.979996), ('2023-11-10', 210.029999, 215.380005, 205.690002, 214.649994, 214.649994), ('2023-11-13', 215.600006, 225.399994, 211.610001, 223.710007, 223.710007), ('2023-11-14', 235.029999, 238.139999, 230.720001, 237.410004, 237.410004), ('2023-11-15', 239.289993, 246.699997, 236.449997, 242.839996, 242.839996), ('2023-11-16', 239.490005, 240.880005, 230.960007, 233.589996, 233.589996), ('2023-11-17', 232.0, 237.389999, 226.539993, 234.300003, 234.300003), ('2023-11-20', 234.039993, 237.100006, 231.020004, 235.600006, 235.600006), ('2023-11-21', 235.039993, 243.619995, 233.339996, 241.199997, 241.199997), ('2023-11-22', 242.039993, 244.009995, 231.399994, 234.210007, 234.210007), ('2023-11-24', 233.75, 238.75, 232.330002, 235.449997, 235.449997), ('2023-11-27', 236.889999, 238.330002, 232.100006, 236.080002, 236.080002), ('2023-11-28', 236.679993, 247.0, 234.009995, 246.720001, 246.720001), ('2023-11-29', 249.210007, 252.75, 242.759995, 244.139999, 244.139999), ('2023-11-30', 245.139999, 245.220001, 236.910004, 240.080002, 240.080002), ('2023-12-01', 233.139999, 240.190002, 231.899994, 238.830002, 238.830002), ('2023-12-04', 235.75, 239.369995, 233.289993, 235.580002, 235.580002), ('2023-12-05', 233.869995, 246.660004, 233.699997, 238.720001, 238.720001), ('2023-12-06', 242.919998, 246.570007, 239.169998, 239.369995, 239.369995), ('2023-12-07', 241.550003, 244.080002, 236.979996, 242.639999, 242.639999), ('2023-12-08', 240.270004, 245.270004, 239.270004, 243.839996, 243.839996), ('2023-12-11', 242.740005, 243.440002, 237.449997, 239.740005, 239.740005), ('2023-12-12', 238.550003, 238.990005, 233.869995, 237.009995, 237.009995), ('2023-12-13', 234.190002, 240.300003, 228.199997, 239.289993, 239.289993), ('2023-12-14', 241.220001, 253.880005, 240.789993, 251.050003, 251.050003), ('2023-12-15', 251.210007, 254.130005, 248.300003, 253.5, 253.5), ('2023-12-18', 253.779999, 258.73999, 251.360001, 252.080002, 252.080002), ('2023-12-19', 253.479996, 258.339996, 253.009995, 257.220001, 257.220001), ('2023-12-20', 256.410004, 259.839996, 247.0, 247.139999, 247.139999), ('2023-12-21', 251.899994, 254.800003, 248.550003, 254.5, 254.5), ('2023-12-22', 256.76001, 258.220001, 251.369995, 252.539993, 252.539993), ('2023-12-26', 254.490005, 257.970001, 252.910004, 256.609985, 256.609985), ('2023-12-27', 258.350006, 263.339996, 257.519989, 261.440002, 261.440002), ('2023-12-28', 263.660004, 265.130005, 252.710007, 253.179993, 253.179993), ('2023-12-29', 255.100006, 255.190002, 247.429993, 248.479996, 248.479996), ('2024-01-02', 250.080002, 251.25, 244.410004, 248.419998, 248.419998), ('2024-01-03', 244.979996, 245.679993, 236.320007, 238.449997, 238.449997), ('2024-01-04', 239.25, 242.699997, 237.729996, 237.929993, 237.929993), ('2024-01-05', 236.860001, 240.119995, 234.899994, 237.490005, 237.490005), ('2024-01-08', 236.139999, 241.25, 235.300003, 240.449997, 240.449997), ('2024-01-09', 238.110001, 238.960007, 232.039993, 234.960007, 234.960007), ('2024-01-10', 235.100006, 235.5, 231.289993, 233.940002, 233.940002), ('2024-01-11', 230.570007, 230.929993, 225.369995, 227.220001, 227.220001), ('2024-01-12', 220.080002, 225.339996, 217.149994, 218.889999, 218.889999), ('2024-01-16', 215.100006, 223.490005, 212.179993, 219.910004, 219.910004), ('2024-01-17', 214.860001, 215.669998, 212.009995, 215.550003, 215.550003), ('2024-01-18', 216.880005, 217.449997, 208.740005, 211.880005, 211.880005), ('2024-01-19', 209.990005, 213.190002, 207.559998, 212.190002, 212.190002), ('2024-01-22', 212.259995, 217.800003, 206.270004, 208.800003, 208.800003), ('2024-01-23', 211.300003, 215.649994, 207.75, 209.139999, 209.139999), ('2024-01-24', 211.880005, 212.729996, 206.770004, 207.830002, 207.830002), ('2024-01-25', 189.699997, 193.0, 180.059998, 182.630005, 182.630005), ('2024-01-26', 185.5, 186.779999, 182.100006, 183.25, 183.25), ('2024-01-29', 185.630005, 191.479996, 183.669998, 190.929993, 190.929993), ('2024-01-30', 195.330002, 196.360001, 190.610001, 191.589996, 191.589996), ('2024-01-31', 187.0, 193.970001, 185.850006, 187.289993, 187.289993), ('2024-02-01', 188.5, 189.880005, 184.279999, 188.860001, 188.860001), ('2024-02-02', 185.039993, 188.690002, 182.0, 187.910004, 187.910004)]\n"
     ]
    }
   ],
   "source": [
    "response_full = openai.chat.completions.create(model=\"gpt-4o\", messages=[{\"role\": \"system\", \"content\": SQL_SYSTEM_PROMPT2},\n",
    "                                                                      {\"role\": \"user\", \"content\": \"Create a trend plot for TSLA's prices over the last year\" }],\n",
    "                                                                      temperature=0) #, logprobs=True, top_logprobs=5\n",
    "\n",
    "print(response_full.choices[0].message.content)\n",
    "\n",
    "#extract the SQL query from the response\n",
    "sql_query = response_full.choices[0].message.content.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "#run the sql query using the conn connection \n",
    "conn = sqlite3.connect('tsla_stock.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Get column names from cursor.description\n",
    "column_names = [description[0] for description in cursor.description]\n",
    "result = cursor.fetchall()\n",
    "result_with_column_names = [column_names] + result\n",
    "print(result_with_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359080b",
   "metadata": {},
   "source": [
    "Based on trying a few other prompts and tasks as well as diagnosing all of the above to make it work, I believe a more robust approach is needed to make this work for an end-user that might not read code or understand intermediate steps. This may be possible in LangChain or with Pandas-AI, but there are also building from scratch or using an existing full-scale agent-based frameworks such as [AutoGen](https://github.com/microsoft/autogen), [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT), [OpenAgents](https://github.com/Significant-Gravitas/AutoGPT) and [crewAI](https://github.com/joaomdmoura/crewAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a1229",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2adc9a9c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
